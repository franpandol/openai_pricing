# OpenAI Pricing API

This Django project provides a RESTful API to calculate costs based on the usage of OpenAI's GPT and image generation models.

## Getting Started

### Prerequisites

To run this project, you'll need:

- Docker
- docker-compose

### Installation

1. Clone the repository:

```bash
git clone https://github.com/franpandol/openai_pricing.git
cd openai_pricing
```


Initial Setup

Before you can start using the API, you'll need to set up the database and create a superuser. You can do this easily using the make command.

Run the following command to seed the database with pricing examples and create a superuser:

```bash

make setup
```

The superuser credentials are only for local development
username: admin
password: admin

Using the API

Once the initial setup is complete, you can start the Django server using:

```bash
make run
```
The API provides endpoints to calculate costs for token-based or image-based requests. Detailed API documentation will be provided once the server is running, accessible at http://localhost:8000.



http://localhost:8000/api/v1/calculate_cost/

Request example
```
{"company": "openai", "endpoint": "/v1/chat/completions", "requestBody": "eyJtb2RlbCI6ImdwdC00IiwibWVzc2FnZXMiOlt7InJvbGUiOiJ1c2VyIiwiY29udGVudCI6ImdpdmUgbWUgYSBoYWlrdSBhYm91dCBwbGFuZXRzIn0seyJyb2xlIjoic3lzdGVtIiwiY29udGVudCI6IlNwaGVyZXMgb2YgbXlzdGlxdWUgZGFuY2UsXG5JbiBjb3NtaWMgYmFsbGV0IHRoZXkgd2hpcmwsXG5QbGFuZXRhcnkgdHJhbmNlLiJ9LHsicm9sZSI6InVzZXIiLCJjb250ZW50IjoiY2FuIHlvdSBpbmNsdWRlIHBsdXRvPyJ9XX0=", "responseBody": "eyJpZCI6ImNoYXRjbXBsLThwelo2VUt6ZmJJVVJPV3o3SXhUM0dsME53ZHhHIiwib2JqZWN0IjoiY2hhdC5jb21wbGV0aW9uIiwiY3JlYXRlZCI6MTcwNzQwMjA3NiwibW9kZWwiOiJncHQtNC0wNjEzIiwiY2hvaWNlcyI6W3siaW5kZXgiOjAsIm1lc3NhZ2UiOnsicm9sZSI6ImFzc2lzdGFudCIsImNvbnRlbnQiOiJFdmVuIHNtYWxsIFBsdXRvLFxuRGFuY2VzIGluIGNlbGVzdGlhbCB3YWx0eixcbkluIHRoZSB2b2lkLCBzbyBtdXRlLiJ9LCJsb2dwcm9icyI6bnVsbCwiZmluaXNoX3JlYXNvbiI6InN0b3AifV0sInVzYWdlIjp7InByb21wdF90b2tlbnMiOjQ1LCJjb21wbGV0aW9uX3Rva2VucyI6MTksInRvdGFsX3Rva2VucyI6NjR9LCJzeXN0ZW1fZmluZ2VycHJpbnQiOm51bGx9"}
```

Response example
```
{"cost": 500}
```

Testing

To run the test suite, use:

```bash
make test
```


# How does it work

The API uses a simple pricing model based on the number of tokens generated by the GPT model and the number of images generated by the image generation model. The cost is calculated based on the usage of the OpenAI API, and the pricing is based on the following assumptions:

The API receives a request with the following parameters:

- company: The company that the request is for. Currently, only "openai" is supported.
- endpoint: The endpoint of the OpenAI API that the request is for.
- requestBody: The request body of the OpenAI API request.
- responseBody: The response body of the OpenAI API request.

the bodies are base64 encoded to simulate the real request and response bodies. 
For the GPT model, the cost is calculated based on the number of tokens generated by the model. The response must contain the number of tokens generated by the model, and the cost is calculated based on the number of tokens.

Examples
```
{
  "company": "openai",
  "endpoint": "/v1/chat/completions",
  "requestBody": "eyJtb2RlbCI6ImdwdC00IiwibWVzc2FnZXMiOlt7InJvbGUiOiJ1c2VyIiwiY29udGVudCI6ImdpdmUgbWUgYSBoYWlrdSBhYm91dCBwbGFuZXRzIn0seyJyb2xlIjoic3lzdGVtIiwiY29udGVudCI6IlNwaGVyZXMgb2YgbXlzdGlxdWUgZGFuY2UsXG5JbiBjb3NtaWMgYmFsbGV0IHRoZXkgd2hpcmwsXG5QbGFuZXRhcnkgdHJhbmNlLiJ9LHsicm9sZSI6InVzZXIiLCJjb250ZW50IjoiY2FuIHlvdSBpbmNsdWRlIHBsdXRvPyJ9XX0=",
  "responseBody": "eyJpZCI6ImNoYXRjbXBsLThwelo2VUt6ZmJJVVJPV3o3SXhUM0dsME53ZHhHIiwib2JqZWN0IjoiY2hhdC5jb21wbGV0aW9uIiwiY3JlYXRlZCI6MTcwNzQwMjA3NiwibW9kZWwiOiJncHQtNC0wNjEzIiwiY2hvaWNlcyI6W3siaW5kZXgiOjAsIm1lc3NhZ2UiOnsicm9sZSI6ImFzc2lzdGFudCIsImNvbnRlbnQiOiJFdmVuIHNtYWxsIFBsdXRvLFxuRGFuY2VzIGluIGNlbGVzdGlhbCB3YWx0eixcbkluIHRoZSB2b2lkLCBzbyBtdXRlLiJ9LCJsb2dwcm9icyI6bnVsbCwiZmluaXNoX3JlYXNvbiI6InN0b3AifV0sInVzYWdlIjp7InByb21wdF90b2tlbnMiOjQ1LCJjb21wbGV0aW9uX3Rva2VucyI6MTksInRvdGFsX3Rva2VucyI6NjR9LCJzeXN0ZW1fZmluZ2VycHJpbnQiOm51bGx9"
}
```

The request body is base64 encoded and represents the following request:

```
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "user",
      "content": "give me a haiku about planets"
    },
    {
      "role": "system",
      "content": "Spheres of mystique dance,\nIn cosmic ballet they whirl,\nPlanetary trance."
    },
    {
      "role": "user",
      "content": "can you include pluto?"
    }
  ]
}
```

The response body is base64 encoded and represents the following response:

```
{
  "id": "chatcmpl-8pzZ6UKzfbIUROWz7IxT3Gl0NwdxG",
  "object": "chat.completion",
  "created": 1707402076,
  "model": "gpt-4-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Even small Pluto,\nDances in celestial waltz,\nIn the void, so mute."
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 45,
    "completion_tokens": 19,
    "total_tokens": 64
  },
  "system_fingerprint": null
}
```

For the image generation model, the cost is calculated based on the number of images generated by the model. The response must contain the number of images generated by the model, and the cost is calculated based on the number of images.

